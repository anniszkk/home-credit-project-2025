{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYoRme1XZCy-",
        "outputId": "fe4eda34-6e0b-426d-9cd9-a2cc74e3c04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Library berhasil di-import ---\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Google Drive berhasil terhubung ---\n",
            "Path data train: /content/drive/MyDrive/Kuliah/HomeCreditProject/application_train.csv\n",
            "Path kamus data: /content/drive/MyDrive/Kuliah/HomeCreditProject/HomeCredit_columns_description.csv\n",
            "\n",
            "--- Data 'application_train.csv' berhasil dimuat ---\n",
            "Bentuk data (baris, kolom): (307511, 122)\n",
            "\n",
            "--- Kamus Data 'HomeCredit_columns_description.csv' berhasil dimuat ---\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Konfigurasi Awal ---\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "print(\"--- Library berhasil di-import ---\")\n",
        "\n",
        "\n",
        "# --- 2. Hubungkan ke Google Drive ---\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"--- Google Drive berhasil terhubung ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- Gagal menghubungkan Google Drive: {e} ---\")\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Kuliah/HomeCreditProject/\"\n",
        "\n",
        "train_path = BASE_PATH + \"application_train.csv\"\n",
        "desc_path = BASE_PATH + \"HomeCredit_columns_description.csv\"\n",
        "\n",
        "print(f\"Path data train: {train_path}\")\n",
        "print(f\"Path kamus data: {desc_path}\")\n",
        "\n",
        "try:\n",
        "    # Muat data latih\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    print(f\"\\n--- Data 'application_train.csv' berhasil dimuat ---\")\n",
        "    print(f\"Bentuk data (baris, kolom): {df_train.shape}\")\n",
        "\n",
        "    # Muat kamus data\n",
        "    df_desc = pd.read_csv(desc_path, encoding='ISO-8859-1')\n",
        "    print(f\"\\n--- Kamus Data 'HomeCredit_columns_description.csv' berhasil dimuat ---\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n--- ERROR: File tidak ditemukan ---\")\n",
        "    print(e)\n",
        "    print(\"\\nPastikan Anda sudah mengunggah file ke Google Drive dan path di 'BASE_PATH' sudah benar.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- ERROR: Terjadi kesalahan saat memuat data: {e} ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisis Variabel TARGET ---\n",
        "\n",
        "if 'df_train' in locals():\n",
        "    print(\"--- Menganalisis Kolom TARGET ---\")\n",
        "\n",
        "    # 1. Cek nilai unik\n",
        "    print(f\"Nilai unik di TARGET: {df_train['TARGET'].unique()}\")\n",
        "\n",
        "    # 2. Hitung jumlah & persentase\n",
        "    target_counts = df_train['TARGET'].value_counts()\n",
        "    target_perc = df_train['TARGET'].value_counts(normalize=True) * 100\n",
        "\n",
        "    print(\"\\nJumlah Klien:\")\n",
        "    print(f\"TARGET 0 (Lancar):     {target_counts.get(0, 0)} klien\")\n",
        "    print(f\"TARGET 1 (Gagal Bayar): {target_counts.get(1, 0)} klien\")\n",
        "\n",
        "    print(\"\\nPersentase Klien:\")\n",
        "    print(f\"TARGET 0 (Lancar):     {target_perc.get(0, 0):.2f}%\")\n",
        "    print(f\"TARGET 1 (Gagal Bayar): {target_perc.get(1, 0):.2f}%\")\n",
        "\n",
        "    # 3. Visualisasi\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(x='TARGET', data=df_train)\n",
        "    plt.title('Distribusi Variabel TARGET', fontsize=16)\n",
        "    plt.xlabel('TARGET (0 = Lancar, 1 = Gagal Bayar)')\n",
        "    plt.ylabel('Jumlah Klien')\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'df_train' tidak ditemukan. Pastikan sel kode pertama berhasil dijalankan. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVhwvwWvbY5m",
        "outputId": "044e2408-00be-42ec-a0f9-a3cc75ac9886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Menganalisis Kolom TARGET ---\n",
            "Nilai unik di TARGET: [1 0]\n",
            "\n",
            "Jumlah Klien:\n",
            "TARGET 0 (Lancar):     282686 klien\n",
            "TARGET 1 (Gagal Bayar): 24825 klien\n",
            "\n",
            "Persentase Klien:\n",
            "TARGET 0 (Lancar):     91.93%\n",
            "TARGET 1 (Gagal Bayar): 8.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---Menganalisis Missing Values ---\n",
        "\n",
        "if 'df_train' in locals():\n",
        "    # 1. Hitung total missing values per kolom\n",
        "    missing_values = df_train.isnull().sum()\n",
        "\n",
        "    # 2. Hitung persentase missing values\n",
        "    missing_percentage = (missing_values / len(df_train)) * 100\n",
        "\n",
        "    missing_data = pd.DataFrame({\n",
        "        'Total Missing': missing_values,\n",
        "        'Percentage (%)': missing_percentage\n",
        "    })\n",
        "\n",
        "    # 3. Urutkan dari yang paling banyak missing\n",
        "    missing_data_sorted = missing_data[missing_data['Total Missing'] > 0].sort_values(\n",
        "        by='Percentage (%)', ascending=False\n",
        "    )\n",
        "\n",
        "    print(f\"--- Menganalisis Missing Values di {len(df_train.columns)} Kolom ---\")\n",
        "    print(f\"Total kolom yang memiliki missing values: {len(missing_data_sorted)}\")\n",
        "    print(\"\\n--- Kolom dengan Missing Values Terbanyak (di atas 0%) ---\")\n",
        "    print(missing_data_sorted)\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'df_train' tidak ditemukan. ---\")"
      ],
      "metadata": {
        "id": "guRYRnFkcFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Memuat Data Uji (Test Data) ---\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Kuliah/HomeCreditProject/\"\n",
        "test_path = BASE_PATH + \"application_test.csv\"\n",
        "\n",
        "try:\n",
        "    df_test = pd.read_csv(test_path)\n",
        "    print(f\"--- Data 'application_test.csv' berhasil dimuat ---\")\n",
        "    print(f\"Bentuk data (baris, kolom): {df_test.shape}\")\n",
        "\n",
        "    # Untuk konsistensi, simpan TARGET dan SK_ID_CURR\n",
        "    train_target = df_train['TARGET']\n",
        "    train_id = df_train['SK_ID_CURR']\n",
        "    test_id = df_test['SK_ID_CURR']\n",
        "\n",
        "    # Gabungkan sementara untuk cleaning\n",
        "    df_full = pd.concat([df_train.drop('TARGET', axis=1), df_test], ignore_index=True)\n",
        "\n",
        "    print(f\"\\nBentuk data gabungan (untuk cleaning): {df_full.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\n--- ERROR: 'application_test.csv' tidak ditemukan di path Anda ---\")\n",
        "    print(\"Pastikan file tersebut ada di folder yang sama.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- ERROR: {e} ---\")"
      ],
      "metadata": {
        "id": "TgkGCBwRcpjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9. Proses Data Cleaning (Imputasi & Dropping) ---\n",
        "\n",
        "if 'df_full' in locals():\n",
        "    print(f\"Bentuk data sebelum cleaning: {df_full.shape}\")\n",
        "\n",
        "    # 1. HAPUS KOLOM DENGAN MISSING > 50%\n",
        "    missing_perc = (df_full.isnull().sum() / len(df_full)) * 100\n",
        "\n",
        "    cols_to_drop = missing_perc[missing_perc > 50].index\n",
        "\n",
        "    print(f\"\\nMenghapus {len(cols_to_drop)} kolom (missing > 50%)...\")\n",
        "    df_full = df_full.drop(columns=cols_to_drop)\n",
        "\n",
        "    print(f\"Bentuk data setelah menghapus kolom: {df_full.shape}\")\n",
        "\n",
        "    # 2. ISI SISANYA (MISSING < 50%)\n",
        "\n",
        "    print(\"\\nMengisi sisa missing values...\")\n",
        "    remaining_missing_cols = df_full.columns[df_full.isnull().any()].tolist()\n",
        "\n",
        "    categorical_cols = df_full[remaining_missing_cols].select_dtypes(include=['object']).columns\n",
        "\n",
        "    numerical_cols = df_full[remaining_missing_cols].select_dtypes(include=['number']).columns\n",
        "\n",
        "    # 3a. Isi Kolom Kategorikal dengan Modus (nilai paling sering muncul)\n",
        "    print(f\"Mengisi {len(categorical_cols)} kolom kategorikal dengan MODUS...\")\n",
        "    for col in categorical_cols:\n",
        "        mode_value = df_full[col].mode()[0]\n",
        "        df_full[col] = df_full[col].fillna(mode_value)\n",
        "\n",
        "    # 3b. Isi Kolom Numerik dengan Median (nilai tengah)\n",
        "    print(f\"Mengisi {len(numerical_cols)} kolom numerik dengan MEDIAN...\")\n",
        "    for col in numerical_cols:\n",
        "        median_value = df_full[col].median()\n",
        "        df_full[col] = df_full[col].fillna(median_value)\n",
        "\n",
        "    print(\"\\n--- PROSES CLEANING SELESAI ---\")\n",
        "\n",
        "    total_missing_after = df_full.isnull().sum().sum()\n",
        "    print(f\"Total missing values di data gabungan sekarang: {total_missing_after}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'df_full' tidak ditemukan. Jalankan sel kode 8 terlebih dahulu. ---\")"
      ],
      "metadata": {
        "id": "zBrAfWPjdd22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10. Data Processing (One-Hot Encoding) ---\n",
        "\n",
        "if 'df_full' in locals():\n",
        "    print(f\"Bentuk data sebelum encoding: {df_full.shape}\")\n",
        "\n",
        "    # 1. Identifikasi kolom kategorikal (tipe 'object')\n",
        "    categorical_cols = df_full.select_dtypes(include=['object']).columns\n",
        "\n",
        "    print(f\"Ditemukan {len(categorical_cols)} kolom kategorikal yang akan di-encode.\")\n",
        "\n",
        "    # 2. Lakukan One-Hot Encoding\n",
        "    df_full_processed = pd.get_dummies(df_full, columns=categorical_cols)\n",
        "\n",
        "    print(f\"Bentuk data setelah encoding: {df_full_processed.shape}\")\n",
        "\n",
        "    # 3. Menyamakan nama kolom\n",
        "    df_full_processed.columns = [\"\".join (c if c.isalnum() else '_' for c in str(x)) for x in df_full_processed.columns]\n",
        "\n",
        "    print(\"Nama kolom telah dibersihkan dan disiapkan untuk model.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'df_full' tidak ditemukan. ---\")"
      ],
      "metadata": {
        "id": "diZ2CjlrfKl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11. Memisahkan Kembali Data ---\n",
        "\n",
        "if 'df_full_processed' in locals() and 'train_target' in locals():\n",
        "    # Pisahkan kembali berdasarkan jumlah baris data train asli\n",
        "    num_train_rows = len(df_train)\n",
        "\n",
        "    # Data latih (fitur)\n",
        "    X = df_full_processed.iloc[:num_train_rows].drop(columns=['SK_ID_CURR'])\n",
        "\n",
        "    # Data uji (fitur)\n",
        "    X_test = df_full_processed.iloc[num_train_rows:].drop(columns=['SK_ID_CURR'])\n",
        "\n",
        "    # Data latih (target)\n",
        "    y = train_target\n",
        "\n",
        "    # Simpan ID untuk referensi (jika diperlukan untuk submisi)\n",
        "    train_ids = train_id\n",
        "    test_ids = test_id\n",
        "\n",
        "    print(f\"Bentuk data latih (X): {X.shape}\")\n",
        "    print(f\"Bentuk data target (y): {y.shape}\")\n",
        "    print(f\"Bentuk data uji (X_test): {X_test.shape}\")\n",
        "\n",
        "    print(\"\\n--- Data siap untuk pemodelan! ---\")\n",
        "    print(\"Variabel Anda sekarang adalah: X, y, X_test\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Gagal memisahkan data. Pastikan Sel 10 (Encoding) berhasil dijalankan. ---\")"
      ],
      "metadata": {
        "id": "Ic3gcIxDh0Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 12. Feature Scaling ---\n",
        "\n",
        "if 'X' in locals() and 'X_test' in locals():\n",
        "    print(\"--- Memulai Feature Scaling ---\")\n",
        "\n",
        "    # 1. Buat object scaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # 2. Fit dan transform HANYA pada data latih (X)\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 3. Transform HANYA pada data uji (X_test)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # 4. Konversi kembali ke DataFrame (opsional, tapi lebih rapi)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "    print(\"--- Feature Scaling Selesai ---\")\n",
        "    print(f\"Bentuk X_scaled (data latih): {X_scaled.shape}\")\n",
        "    print(f\"Bentuk X_test_scaled (data uji): {X_test_scaled.shape}\")\n",
        "    print(\"\\nData Anda sekarang 100% siap untuk pemodelan!\")\n",
        "    print(\"Variabel Anda adalah: X_scaled, y, X_test_scaled\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X' dan 'X_test' tidak ditemukan. ---\")\n",
        "    print(\"Pastikan Sel 11 (Pemisahan Final) sudah dijalankan.\")"
      ],
      "metadata": {
        "id": "HNTiilzliFz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# --- 13. Membagi Data Latih menjadi Latih & Validasi ---\n",
        "\n",
        "if 'X_scaled' in locals() and 'y' in locals():\n",
        "    # Membagi 80% untuk latih, 20% untuk validasi\n",
        "    # random_state=42 untuk memastikan hasil bisa direproduksi\n",
        "    #\n",
        "    # stratify=y\n",
        "    # Ini memastikan bahwa rasio 8.07% (gagal bayar) tetap ada\n",
        "    # di kedua set data (latih dan validasi).\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_scaled,\n",
        "        y,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"--- Data berhasil dibagi ---\")\n",
        "    print(f\"Bentuk X_train: {X_train.shape}\")\n",
        "    print(f\"Bentuk y_train: {y_train.shape}\")\n",
        "    print(f\"Bentuk X_val:   {X_val.shape}\")\n",
        "    print(f\"Bentuk y_val:   {y_val.shape}\")\n",
        "\n",
        "    print(\"\\nDistribusi TARGET di y_train (Latih):\")\n",
        "    print(y_train.value_counts(normalize=True) * 100)\n",
        "\n",
        "    print(\"\\nDistribusi TARGET di y_val (Validasi):\")\n",
        "    print(y_val.value_counts(normalize=True) * 100)\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X_scaled' dan 'y' tidak ditemukan. ---\")\n",
        "    print(\"Pastikan Sel 12 (Feature Scaling) sudah dijalankan.\")"
      ],
      "metadata": {
        "id": "ZJ8gdqHDio4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 14. Langkah 8 (Pemodelan) & 9 (Evaluasi): Regresi Logistik ---\n",
        "\n",
        "if 'X_train' in locals():\n",
        "    print(\"--- 1. Melatih Model Regresi Logistik ---\")\n",
        "\n",
        "    # Menggunakan class_weight='balanced' untuk mengatasi imbalanced dataset\n",
        "    # solver='liblinear' adalah solver yang baik untuk dataset < 1jt baris\n",
        "    model_lr = LogisticRegression(\n",
        "        random_state=42,\n",
        "        class_weight='balanced',\n",
        "        solver='liblinear'\n",
        "    )\n",
        "\n",
        "    # Latih model\n",
        "    model_lr.fit(X_train, y_train)\n",
        "\n",
        "    print(\"--- Model berhasil dilatih ---\")\n",
        "\n",
        "    # --- 2. Membuat Prediksi & Evaluasi ---\n",
        "    print(\"\\n--- 2. Mengevaluasi Model pada Data Validasi ---\")\n",
        "\n",
        "    # Buat prediksi pada data validasi (X_val)\n",
        "    y_pred_lr = model_lr.predict(X_val)\n",
        "\n",
        "    # Buat probabilitas prediksi (dibutuhkan untuk AUC-ROC)\n",
        "    # [:, 1] mengambil probabilitas untuk kelas '1' (Gagal Bayar)\n",
        "    y_proba_lr = model_lr.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # --- 3. Menampilkan Metrik Evaluasi ---\n",
        "    print(\"\\n--- Hasil Evaluasi (Baseline Model) ---\")\n",
        "\n",
        "    # Akurasi\n",
        "    acc = accuracy_score(y_val, y_pred_lr)\n",
        "    print(f\"Akurasi: {acc * 100:.2f}%\")\n",
        "    print(f\"(Catatan: Akurasi '91.93%' bisa didapat model bodoh. Jadi, ini bukan metrik utama kita.)\")\n",
        "\n",
        "    # Metrik Utama untuk Imbalanced Data\n",
        "    print(\"\\n--- Metrik Kinerja Bisnis ---\")\n",
        "\n",
        "    # AUC-ROC: Metrik terbaik untuk performa imbalanced\n",
        "    auc = roc_auc_score(y_val, y_proba_lr)\n",
        "    print(f\"SKOR AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # Recall: Seberapa baik MENEMUKAN klien Gagal Bayar? (TP / (TP + FN))\n",
        "    rec = recall_score(y_val, y_pred_lr)\n",
        "    print(f\"Recall:       {rec:.4f} (Model ini menemukan {(rec * 100):.2f}% dari semua klien Gagal Bayar)\")\n",
        "\n",
        "    # Precision: Dari yang diprediksi Gagal Bayar, berapa yang benar? (TP / (TP + FP))\n",
        "    prec = precision_score(y_val, y_pred_lr)\n",
        "    print(f\"Precision:    {prec:.4f} (Dari yang diprediksi Gagal Bayar, {(prec * 100):.2f}% benar)\")\n",
        "\n",
        "    # F1-Score: Rata-rata harmonik Precision dan Recall\n",
        "    f1 = f1_score(y_val, y_pred_lr)\n",
        "    print(f\"F1-Score:     {f1:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\n--- Confusion Matrix ---\")\n",
        "    cm = confusion_matrix(y_val, y_pred_lr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)'])\n",
        "    plt.ylabel('Aktual')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.title('Confusion Matrix - Regresi Logistik', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X_train' tidak ditemukan. ---\")\n",
        "    print(\"Pastikan Sel 13 (Split Data) sudah dijalankan.\")"
      ],
      "metadata": {
        "id": "cqRTZJ8xjpKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix, accuracy_score\n",
        "\n",
        "# --- 15. Langkah 8 (Metode Lain): LightGBM ---\n",
        "\n",
        "if 'X_train' in locals():\n",
        "    print(\"--- 1. Melatih Model LightGBM (LGBM) ---\")\n",
        "\n",
        "    model_lgbm = lgb.LGBMClassifier(\n",
        "        random_state=42,\n",
        "        class_weight='balanced',\n",
        "        n_estimators=200,  # Jumlah \"pohon\" yang akan dibuat\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=31\n",
        "    )\n",
        "\n",
        "    # Latih model\n",
        "    # gunakan X_train dan y_train yang sama\n",
        "    model_lgbm.fit(X_train, y_train)\n",
        "\n",
        "    print(\"--- Model LGBM berhasil dilatih ---\")\n",
        "\n",
        "    # --- 2. Mengevaluasi Model LGBM ---\n",
        "    print(\"\\n--- 2. Mengevaluasi Model LGBM pada Data Validasi ---\")\n",
        "\n",
        "    y_pred_lgbm = model_lgbm.predict(X_val)\n",
        "    y_proba_lgbm = model_lgbm.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # --- 3. Menampilkan Metrik Evaluasi ---\n",
        "    print(\"\\n--- Hasil Evaluasi (LightGBM) ---\")\n",
        "\n",
        "    acc_lgbm = accuracy_score(y_val, y_pred_lgbm)\n",
        "    print(f\"Akurasi: {acc_lgbm * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Metrik Kinerja Bisnis (LightGBM) ---\")\n",
        "\n",
        "    auc_lgbm = roc_auc_score(y_val, y_proba_lgbm)\n",
        "    print(f\"SKOR AUC-ROC: {auc_lgbm:.4f}  (Baseline LR: 0.7454)\")\n",
        "\n",
        "    rec_lgbm = recall_score(y_val, y_pred_lgbm)\n",
        "    print(f\"Recall:       {rec_lgbm:.4f}  (Baseline LR: 0.6749)\")\n",
        "\n",
        "    prec_lgbm = precision_score(y_val, y_pred_lgbm)\n",
        "    print(f\"Precision:    {prec_lgbm:.4f}  (Baseline LR: 0.1603)\")\n",
        "\n",
        "    f1_lgbm = f1_score(y_val, y_pred_lgbm)\n",
        "    print(f\"F1-Score:     {f1_lgbm:.4f}  (Baseline LR: 0.2590)\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\n--- Confusion Matrix (LightGBM) ---\")\n",
        "    cm_lgbm = confusion_matrix(y_val, y_pred_lgbm)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_lgbm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)'])\n",
        "    plt.ylabel('Aktual')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.title('Confusion Matrix - LightGBM', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X_train' tidak ditemukan. ---\")\n",
        "    print(\"Pastikan Sel 13 (Split Data) sudah dijalankan.\")"
      ],
      "metadata": {
        "id": "bYJYx65uk_2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# --- 16. Langkah 8 (Hyperparameter Tuning): VERSI GPU ---\n",
        "\n",
        "if 'X_train' in locals():\n",
        "    print(\"--- 1. Memulai Hyperparameter Tuning untuk LGBM (VERSI GPU) ---\")\n",
        "\n",
        "    # 1. Tentukan model dasar\n",
        "    lgbm_tuner = lgb.LGBMClassifier(\n",
        "        random_state=42,\n",
        "        class_weight='balanced',\n",
        "        device='gpu'\n",
        "    )\n",
        "\n",
        "    # 2. Tentukan 'param_dist' - rentang hyperparameter yang ingin dicoba\n",
        "    param_dist = {\n",
        "        'n_estimators': randint(100, 400),\n",
        "        'learning_rate': uniform(0.01, 0.1),\n",
        "        'num_leaves': randint(20, 50),\n",
        "        'colsample_bytree': uniform(0.6, 0.4),\n",
        "        'subsample': uniform(0.6, 0.4)\n",
        "    }\n",
        "\n",
        "    # 3. Inisialisasi RandomizedSearchCV\n",
        "    # n_iter=10: Akan mencoba 10 kombinasi acak.\n",
        "    # cv=3: 3-fold cross-validation\n",
        "    # scoring='roc_auc': Metrik utama\n",
        "    # n_jobs=-1: Gunakan semua core CPU\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        lgbm_tuner,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=10,\n",
        "        cv=3,\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"Melatih 10 model kandidat di GPU... (Ini akan jauh lebih cepat)\")\n",
        "\n",
        "    # 4. Latih tuner\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n--- Tuning Selesai ---\")\n",
        "\n",
        "    # 5. Tampilkan hyperparameter terbaik\n",
        "    print(\"Hyperparameter terbaik yang ditemukan:\")\n",
        "    print(random_search.best_params_)\n",
        "    print(f\"\\nSkor AUC-ROC terbaik (dari CV): {random_search.best_score_:.4f}\")\n",
        "\n",
        "    # 6. Simpan model terbaik\n",
        "    best_lgbm_tuned = random_search.best_estimator_\n",
        "\n",
        "    # --- 7. Evaluasi Model yang Sudah di-Tune ---\n",
        "    print(\"\\n--- Mengevaluasi Model Tuned pada Data Validasi ---\")\n",
        "\n",
        "    y_pred_tuned = best_lgbm_tuned.predict(X_val)\n",
        "    y_proba_tuned = best_lgbm_tuned.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    print(\"\\n--- Hasil Evaluasi (LGBM Tuned) ---\")\n",
        "\n",
        "    auc_tuned = roc_auc_score(y_val, y_proba_tuned)\n",
        "    print(f\"SKOR AUC-ROC: {auc_tuned:.4f}  (Baseline LGBM: 0.7547)\")\n",
        "\n",
        "    rec_tuned = recall_score(y_val, y_pred_tuned)\n",
        "    print(f\"Recall:       {rec_tuned:.4f}  (Baseline LGBM: 0.6743)\")\n",
        "\n",
        "    prec_tuned = precision_score(y_val, y_pred_tuned)\n",
        "    print(f\"Precision:    {prec_tuned:.4f}  (Baseline LGBM: 0.1669)\")\n",
        "\n",
        "    f1_tuned = f1_score(y_val, y_pred_tuned)\n",
        "    print(f\"F1-Score:     {f1_tuned:.4f}  (Baseline LGBM: 0.2676)\")\n",
        "\n",
        "      # Confusion Matrix\n",
        "    print(\"\\n--- Confusion Matrix (LightGBM) ---\")\n",
        "    cm_lgbm = confusion_matrix(y_val, y_pred_tuned)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_lgbm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)'])\n",
        "    plt.ylabel('Aktual')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.title('Confusion Matrix - LightGBM', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X_train' tidak ditemukan. ---\")\n",
        "    print(\"Pastikan Sel 13 (Split Data) sudah dijalankan.\")"
      ],
      "metadata": {
        "id": "IfRyRLXQmoQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "dTkA94Knox6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 17. Langkah 7 (Feature Engineering): previous_application.csv ---\n",
        "\n",
        "if 'X_scaled' in locals():\n",
        "    print(\"--- 1. Memuat Data Pinjaman Sebelumnya ---\")\n",
        "\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Kuliah/HomeCreditProject/\"\n",
        "    prev_app_path = BASE_PATH + \"previous_application.csv\"\n",
        "\n",
        "    try:\n",
        "        df_prev_app = pd.read_csv(prev_app_path)\n",
        "        print(f\"Bentuk data previous_application: {df_prev_app.shape}\")\n",
        "\n",
        "        # --- 2. Proses One-Hot Encoding ---\n",
        "        df_prev_app['prev_app_refused'] = (df_prev_app['NAME_CONTRACT_STATUS'] == 'Refused').astype(int)\n",
        "\n",
        "        # --- 3. Proses Agregasi  ---\n",
        "        print(\"\\n--- 3. Melakukan Agregasi (groupby SK_ID_CURR) ---\")\n",
        "\n",
        "        agg_functions = {\n",
        "            'SK_ID_PREV': ['count'],\n",
        "            'AMT_ANNUITY': ['mean', 'max'],\n",
        "            'AMT_APPLICATION': ['mean', 'max'],\n",
        "            'AMT_CREDIT': ['mean', 'max'],\n",
        "            'AMT_GOODS_PRICE': ['mean', 'max'],\n",
        "            'DAYS_DECISION': ['mean', 'min'],\n",
        "            'prev_app_refused': ['mean', 'sum']\n",
        "        }\n",
        "\n",
        "        # Lakukan agregasi. df_prev_agg akan memiliki SK_ID_CURR sebagai index\n",
        "        df_prev_agg = df_prev_app.groupby('SK_ID_CURR').agg(agg_functions)\n",
        "\n",
        "        # Merapikan nama kolom\n",
        "        df_prev_agg.columns = ['prev_app_' + '_'.join(col).strip() for col in df_prev_agg.columns.values]\n",
        "\n",
        "        print(f\"Bentuk data agregat: {df_prev_agg.shape}\")\n",
        "\n",
        "        # --- 4. Menggabungkan ke Data Latih & Uji Kita ---\n",
        "        print(\"\\n--- 4. Menggabungkan Fitur Baru ke X_scaled dan X_test_scaled ---\")\n",
        "\n",
        "        # 'X_scaled' memiliki index 0-based. 'train_id' memiliki SK_ID_CURR.\n",
        "        # atur index X_scaled menjadi SK_ID_CURR untuk join\n",
        "\n",
        "        # Salin data\n",
        "        X_scaled_new = X_scaled.copy()\n",
        "        X_test_scaled_new = X_test_scaled.copy()\n",
        "\n",
        "        # Atur index ke SK_ID_CURR menggunakan 'train_id' & 'test_id'\n",
        "        X_scaled_new.index = train_id # dari Sel 11\n",
        "        X_test_scaled_new.index = test_id # dari Sel 11\n",
        "\n",
        "        # Sekarang join berdasarkan INDEX\n",
        "        # df_prev_agg juga memiliki SK_ID_CURR sebagai index\n",
        "        X_scaled_new = X_scaled_new.join(df_prev_agg, how='left')\n",
        "        X_test_scaled_new = X_test_scaled_new.join(df_prev_agg, how='left')\n",
        "\n",
        "        print(f\"Bentuk X_scaled_new (latih): {X_scaled_new.shape}\")\n",
        "        print(f\"Bentuk X_test_scaled_new (uji): {X_test_scaled_new.shape}\")\n",
        "\n",
        "        # --- 5. Cleaning Terakhir (Fillna) ---\n",
        "        # Klien yang tidak punya riwayat di prev_app akan memiliki NaN\n",
        "        print(\"\\n--- 5. Mengisi NaN setelah join ---\")\n",
        "        X_scaled_new = X_scaled_new.fillna(0)\n",
        "        X_test_scaled_new = X_test_scaled_new.fillna(0)\n",
        "\n",
        "        # Pastikan kolom konsisten\n",
        "        X_test_scaled_new = X_test_scaled_new[X_scaled_new.columns]\n",
        "\n",
        "        print(\"\\n--- Feature Engineering Selesai ---\")\n",
        "        print(f\"Jumlah fitur baru: {len(df_prev_agg.columns)}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n--- ERROR: 'previous_application.csv' tidak ditemukan. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERROR: {e} ---\")\n",
        "else:\n",
        "    print(\"\\n--- Variabel 'X_scaled' tidak ditemukan. Jalankan Sel 12. ---\")"
      ],
      "metadata": {
        "id": "BJwZxXw-qPoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 18. Split Ulang Data & Latih Ulang Model\n",
        "if 'X_scaled_new' in locals():\n",
        "    print(\"--- 1. Melakukan Split Ulang (dengan fitur baru) ---\")\n",
        "\n",
        "    # Gunakan parameter split yang SAMA PERSIS (random_state=42, stratify=y)\n",
        "    X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(\n",
        "        X_scaled_new,\n",
        "        y, # 'y' (target) tidak berubah\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"--- 2. Melatih Ulang Model LGBM Terbaik (best_lgbm_tuned) ---\")\n",
        "\n",
        "    # Pastikan variabel 'best_lgbm_tuned' ada\n",
        "    if 'best_lgbm_tuned' in locals():\n",
        "        # Latih ulang model pada data yang lebih kaya\n",
        "        best_lgbm_tuned.fit(X_train_new, y_train_new)\n",
        "\n",
        "        print(\"--- Model berhasil dilatih ulang ---\")\n",
        "\n",
        "        # --- 3. Evaluasi Model dengan Fitur Baru ---\n",
        "        print(\"\\n--- Mengevaluasi Model (dgn Fitur Baru) pada Data Validasi ---\")\n",
        "\n",
        "        y_pred_new = best_lgbm_tuned.predict(X_val_new)\n",
        "        y_proba_new = best_lgbm_tuned.predict_proba(X_val_new)[:, 1]\n",
        "\n",
        "        print(\"\\n--- Hasil Evaluasi (LGBM + Fitur Baru) ---\")\n",
        "\n",
        "        auc_new = roc_auc_score(y_val_new, y_proba_new)\n",
        "        print(f\"SKOR AUC-ROC BARU: {auc_new:.4f}  (Sebelumnya: 0.7553)\")\n",
        "\n",
        "        rec_new = recall_score(y_val_new, y_pred_new)\n",
        "        print(f\"Recall BARU:       {rec_new:.4f}  (Sebelumnya: 0.6802)\")\n",
        "\n",
        "        prec_new = precision_score(y_val_new, y_pred_new)\n",
        "        print(f\"Precision BARU:    {prec_new:.4f}  (Sebelumnya: 0.1663)\")\n",
        "\n",
        "        # Tampilkan CM baru\n",
        "        cm_new = confusion_matrix(y_val_new, y_pred_new)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "\n",
        "        sns.heatmap(cm_new, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                    yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)']) # Typo 'S' sudah dihapus\n",
        "        # ---------------------------------\n",
        "\n",
        "        plt.ylabel('Aktual')\n",
        "        plt.xlabel('Prediksi')\n",
        "        plt.title('Confusion Matrix - LGBM + Fitur Baru', fontsize=16)\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"\\n--- ERROR: 'best_lgbm_tuned' tidak ditemukan. Jalankan Sel 16 (Tuning) terlebih dahulu. ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- ERROR: 'X_scaled_new' tidak ditemukan. Jalankan Sel 17 (Feature Engineering) terlebih dahulu. ---\")"
      ],
      "metadata": {
        "id": "mbLB1xUtrKNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 19. Langkah 7 (Feature Engineering): bureau_balance.csv ---\n",
        "\n",
        "print(\"--- 1. Memuat bureau_balance.csv ---\")\n",
        "bureau_balance_path = BASE_PATH + \"bureau_balance.csv\"\n",
        "\n",
        "try:\n",
        "    df_bureau_balance = pd.read_csv(bureau_balance_path)\n",
        "\n",
        "    print(f\"Bentuk data bureau_balance: {df_bureau_balance.shape}\")\n",
        "\n",
        "    # --- 2. One-Hot Encoding Sederhana ---\n",
        "    # Ubah status kredit menjadi angka\n",
        "    df_bureau_balance = pd.get_dummies(df_bureau_balance, columns=['STATUS'], dummy_na=True)\n",
        "\n",
        "    # --- 3. Agregasi Tahap 1 (per SK_ID_BUREAU) ---\n",
        "    print(\"--- 3. Melakukan Agregasi (groupby SK_ID_BUREAU) ---\")\n",
        "\n",
        "    # - Berapa bulan histori kreditnya? (count)\n",
        "    # - Berapa rata-rata status kreditnya? (mean)\n",
        "\n",
        "    agg_bureau_balance = {\n",
        "        'MONTHS_BALANCE': ['min', 'max', 'count'],\n",
        "    }\n",
        "\n",
        "    # Ambil semua kolom status (hasil OHE)\n",
        "    status_cols = [col for col in df_bureau_balance.columns if col.startswith('STATUS_')]\n",
        "    for col in status_cols:\n",
        "        agg_bureau_balance[col] = ['mean', 'sum']\n",
        "\n",
        "    # Lakukan agregasi\n",
        "    df_bureau_balance_agg = df_bureau_balance.groupby('SK_ID_BUREAU').agg(agg_bureau_balance)\n",
        "\n",
        "    # Rapikan nama kolom\n",
        "    df_bureau_balance_agg.columns = ['bureau_bal_' + '_'.join(col).strip() for col in df_bureau_balance_agg.columns.values]\n",
        "\n",
        "    print(f\"Bentuk data agregat bureau_balance: {df_bureau_balance_agg.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\n--- ERROR: 'bureau_balance.csv' tidak ditemukan. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- ERROR: {e} ---\")"
      ],
      "metadata": {
        "id": "-Hw03fTqta5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 20. Langkah 7 (Feature Engineering): bureau.csv (2) ---\n",
        "\n",
        "if 'df_bureau_balance_agg' in locals():\n",
        "    print(\"--- 1. Memuat bureau.csv ---\")\n",
        "    bureau_path = BASE_PATH + \"bureau.csv\"\n",
        "\n",
        "    try:\n",
        "        df_bureau = pd.read_csv(bureau_path)\n",
        "        print(f\"Bentuk data bureau: {df_bureau.shape}\")\n",
        "\n",
        "        # --- 2. Gabungkan dengan bureau_balance_agg ---\n",
        "        df_bureau_full = df_bureau.join(df_bureau_balance_agg, how='left', on='SK_ID_BUREAU')\n",
        "\n",
        "        # Isi NaN (pinjaman tanpa riwayat bulanan) dengan 0\n",
        "        df_bureau_full = df_bureau_full.fillna(0)\n",
        "\n",
        "        # --- 3. Agregasi Tahap 2 (per SK_ID_CURR) ---\n",
        "        print(\"--- 3. Melakukan Agregasi (groupby SK_ID_CURR) ---\")\n",
        "\n",
        "        # - Rata-rata keterlambatan, jumlah kredit, dll.\n",
        "\n",
        "        # OHE sederhana untuk kredit aktif/tutup\n",
        "        df_bureau_full['bureau_credit_active'] = (df_bureau_full['CREDIT_ACTIVE'] == 'Active').astype(int)\n",
        "        df_bureau_full['bureau_credit_closed'] = (df_bureau_full['CREDIT_ACTIVE'] == 'Closed').astype(int)\n",
        "\n",
        "        bureau_agg_functions = {\n",
        "            'SK_ID_BUREAU': ['count'],\n",
        "            'DAYS_CREDIT': ['mean', 'max', 'min'],\n",
        "            'CREDIT_DAY_OVERDUE': ['mean', 'max'],\n",
        "            'AMT_CREDIT_SUM': ['mean', 'sum'],\n",
        "            'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
        "            'AMT_CREDIT_SUM_OVERDUE': ['mean', 'sum'],\n",
        "            'bureau_credit_active': ['mean', 'sum'],\n",
        "            'bureau_credit_closed': ['mean', 'sum'],\n",
        "        }\n",
        "\n",
        "        # Ambil kolom agregat dari bureau_balance\n",
        "        balance_agg_cols = [col for col in df_bureau_full.columns if col.startswith('bureau_bal_')]\n",
        "        for col in balance_agg_cols:\n",
        "            bureau_agg_functions[col] = ['mean'] # Ambil rata-ratanya\n",
        "\n",
        "        # Lakukan agregasi\n",
        "        df_bureau_agg = df_bureau_full.groupby('SK_ID_CURR').agg(bureau_agg_functions)\n",
        "\n",
        "        # Rapikan nama kolom\n",
        "        df_bureau_agg.columns = ['bureau_' + '_'.join(col).strip() for col in df_bureau_agg.columns.values]\n",
        "\n",
        "        print(f\"Bentuk data agregat bureau: {df_bureau_agg.shape}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n--- ERROR: 'bureau.csv' tidak ditemukan. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERROR: {e} ---\")\n",
        "else:\n",
        "    print(\"\\n--- ERROR: 'df_bureau_balance_agg' tidak ditemukan. Jalankan Sel 19. ---\")"
      ],
      "metadata": {
        "id": "OWwHbZocuSyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 21. Gabung Ulang & Latih Ulang Model ---\n",
        "\n",
        "if 'X_scaled_new' in locals() and 'df_bureau_agg' in locals():\n",
        "\n",
        "    # --- 1. Menggabungkan Fitur Baru ---\n",
        "    print(\"--- 1. Menggabungkan Fitur Bureau ke Data Utama ---\")\n",
        "\n",
        "    # gabungkan ke X_scaled_new (yang sudah punya fitur prev_app)\n",
        "    # Gunakan index (SK_ID_CURR)\n",
        "    X_scaled_final = X_scaled_new.join(df_bureau_agg, how='left')\n",
        "    X_test_scaled_final = X_test_scaled_new.join(df_bureau_agg, how='left')\n",
        "\n",
        "    print(f\"Bentuk data latih final: {X_scaled_final.shape}\")\n",
        "    print(f\"Bentuk data uji final: {X_test_scaled_final.shape}\")\n",
        "\n",
        "    # --- 2. Cleaning Terakhir (Fillna) ---\n",
        "    print(\"--- 2. Mengisi NaN setelah join ---\")\n",
        "    # Klien yang tidak punya riwayat di bureau.csv akan memiliki NaN\n",
        "    X_scaled_final = X_scaled_final.fillna(0)\n",
        "    X_test_scaled_final = X_test_scaled_final.fillna(0)\n",
        "\n",
        "    # Pastikan kolom konsisten\n",
        "    X_test_scaled_final = X_test_scaled_final[X_scaled_final.columns]\n",
        "\n",
        "    # --- 3. Split Ulang Data & Latih Ulang ---\n",
        "    print(\"\\n--- 3. Melakukan Split Ulang (dengan fitur baru) ---\")\n",
        "\n",
        "    X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
        "        X_scaled_final, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"--- 4. Melatih Ulang Model LGBM Terbaik (best_lgbm_tuned) ---\")\n",
        "\n",
        "    if 'best_lgbm_tuned' in locals():\n",
        "        best_lgbm_tuned.fit(X_train_final, y_train_final)\n",
        "\n",
        "        print(\"--- Model berhasil dilatih ulang ---\")\n",
        "\n",
        "        # --- 5. Evaluasi Model Final ---\n",
        "        print(\"\\n--- Mengevaluasi Model (dgn Fitur Bureau) pada Data Validasi ---\")\n",
        "\n",
        "        y_pred_final = best_lgbm_tuned.predict(X_val_final)\n",
        "        y_proba_final = best_lgbm_tuned.predict_proba(X_val_final)[:, 1]\n",
        "\n",
        "        print(\"\\n--- Hasil Evaluasi (LGBM + Fitur PrevApp + Fitur Bureau) ---\")\n",
        "\n",
        "        auc_final = roc_auc_score(y_val_final, y_proba_final)\n",
        "        print(f\"SKOR AUC-ROC FINAL: {auc_final:.4f}  (Sebelumnya: 0.7609)\")\n",
        "\n",
        "        rec_final = recall_score(y_val_final, y_pred_final)\n",
        "        print(f\"Recall FINAL:       {rec_final:.4f}  (Sebelumnya: 0.6872)\")\n",
        "\n",
        "        prec_final = precision_score(y_val_final, y_pred_final)\n",
        "        print(f\"Precision FINAL:    {prec_final:.4f}  (Sebelumnya: 0.1697)\")\n",
        "\n",
        "        # Tampilkan CM baru\n",
        "        cm_final = confusion_matrix(y_val_final, y_pred_final)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                    yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)'])\n",
        "        plt.ylabel('Aktual')\n",
        "        plt.xlabel('Prediksi')\n",
        "        plt.title('Confusion Matrix - LGBM + Semua Fitur', fontsize=16)\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"\\n--- ERROR: 'best_lgbm_tuned' tidak ditemukan. Jalankan Sel 16 (Tuning) terlebih dahulu. ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- ERROR: Data yang dibutuhkan tidak ditemukan. Jalankan Sel 17, 19, 20. ---\")"
      ],
      "metadata": {
        "id": "6E95U0C7uun7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 22. Langkah 7 (Feature Engineering): installments_payments.csv ---\n",
        "\n",
        "print(\"--- 1. Memuat installments_payments.csv ---\")\n",
        "installments_path = BASE_PATH + \"installments_payments.csv\"\n",
        "\n",
        "try:\n",
        "    df_installments = pd.read_csv(installments_path)\n",
        "    print(f\"Bentuk data installments_payments: {df_installments.shape}\")\n",
        "\n",
        "    # --- 2. Membuat Fitur Perilaku ---\n",
        "    # Fitur 1: Seberapa cepat/lambat klien membayar?\n",
        "    df_installments['payment_diff'] = df_installments['DAYS_ENTRY_PAYMENT'] - df_installments['DAYS_INSTALMENT']\n",
        "\n",
        "    # Fitur 2: Apakah klien membayar penuh?\n",
        "    df_installments['payment_amt_diff'] = df_installments['AMT_PAYMENT'] - df_installments['AMT_INSTALMENT']\n",
        "\n",
        "    # --- 3. Agregasi Tahap 1 (per SK_ID_PREV) ---\n",
        "    print(\"--- 3. Melakukan Agregasi (groupby SK_ID_PREV) ---\")\n",
        "\n",
        "    installments_agg_functions = {\n",
        "        'NUM_INSTALMENT_NUMBER': ['count'], # Hitung jumlah total cicilan\n",
        "        # ---------------------------------\n",
        "        'payment_diff': ['mean', 'max', 'sum'], # Rata-rata, maks, total keterlambatan\n",
        "        'payment_amt_diff': ['mean', 'max', 'sum'], # Rata-rata, maks, total kurang bayar\n",
        "        'AMT_PAYMENT': ['sum'],\n",
        "        'AMT_INSTALMENT': ['sum']\n",
        "    }\n",
        "\n",
        "    df_installments_agg = df_installments.groupby('SK_ID_PREV').agg(installments_agg_functions)\n",
        "\n",
        "    # Rapikan nama kolom\n",
        "    df_installments_agg.columns = ['install_' + '_'.join(col).strip() for col in df_installments_agg.columns.values]\n",
        "\n",
        "    print(f\"Bentuk data agregat installments: {df_installments_agg.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\n--- ERROR: 'installments_payments.csv' tidak ditemukan. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- ERROR: {e} ---\")"
      ],
      "metadata": {
        "id": "bOT4JyvgxiJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 23. Langkah 7 (Feature Engineering): Agregasi Tahap 2 (per SK_ID_CURR) ---\n",
        "\n",
        "if 'df_prev_app' in locals() and 'df_installments_agg' in locals():\n",
        "    print(\"--- 1. Mengambil mapping ID dari previous_application ---\")\n",
        "\n",
        "    # Ambil mapping SK_ID_PREV -> SK_ID_CURR\n",
        "    prev_app_ids = df_prev_app[['SK_ID_PREV', 'SK_ID_CURR']].copy()\n",
        "\n",
        "    # --- 2. Gabungkan Agregasi Tahap 1 dengan Mapping ID ---\n",
        "    df_installments_with_curr = prev_app_ids.join(df_installments_agg, how='left', on='SK_ID_PREV')\n",
        "\n",
        "    # --- 3. Agregasi Tahap 2 (per SK_ID_CURR) ---\n",
        "    print(\"--- 3. Melakukan Agregasi (groupby SK_ID_CURR) ---\")\n",
        "\n",
        "    # ambil rata-rata dari semua pinjaman sebelumnya\n",
        "    # Ubah nama kolom agar tidak bentrok\n",
        "    agg_cols = [col for col in df_installments_with_curr.columns if col.startswith('install_')]\n",
        "\n",
        "    # Agregasi final: ambil rata-rata, min, max, sum dari fitur agregat\n",
        "    final_agg_functions = {}\n",
        "    for col in agg_cols:\n",
        "        final_agg_functions[col] = ['mean', 'max', 'sum']\n",
        "\n",
        "    df_installments_agg_final = df_installments_with_curr.groupby('SK_ID_CURR').agg(final_agg_functions)\n",
        "\n",
        "    # Rapikan nama kolom\n",
        "    df_installments_agg_final.columns = ['_'.join(col).strip() for col in df_installments_agg_final.columns.values]\n",
        "\n",
        "    print(f\"Bentuk data agregat final installments: {df_installments_agg_final.shape}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- ERROR: Data 'df_prev_app' atau 'df_installments_agg' tidak ditemukan. ---\")"
      ],
      "metadata": {
        "id": "tYrb0vtu1efM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 24. Gabung Ulang & Latih Ulang Model (Final) ---\n",
        "\n",
        "if 'X_scaled_final' in locals() and 'df_installments_agg_final' in locals():\n",
        "\n",
        "    # --- 1. Menggabungkan Fitur Baru ---\n",
        "    print(\"--- 1. Menggabungkan Fitur Installments ke Data Utama ---\")\n",
        "\n",
        "    # gabungkan ke X_scaled_final (yang sudah punya fitur prev_app & bureau)\n",
        "    X_scaled_ultra = X_scaled_final.join(df_installments_agg_final, how='left')\n",
        "    X_test_scaled_ultra = X_test_scaled_final.join(df_installments_agg_final, how='left')\n",
        "\n",
        "    print(f\"Bentuk data latih ultra: {X_scaled_ultra.shape}\")\n",
        "    print(f\"Bentuk data uji ultra: {X_test_scaled_ultra.shape}\")\n",
        "\n",
        "    # --- 2. Cleaning Terakhir (Fillna) ---\n",
        "    print(\"--- 2. Mengisi NaN setelah join ---\")\n",
        "    X_scaled_ultra = X_scaled_ultra.fillna(0)\n",
        "    X_test_scaled_ultra = X_test_scaled_ultra.fillna(0)\n",
        "\n",
        "    # Pastikan kolom konsisten\n",
        "    X_test_scaled_ultra = X_test_scaled_ultra[X_scaled_ultra.columns]\n",
        "\n",
        "    # --- 3. Split Ulang Data & Latih Ulang ---\n",
        "    print(\"\\n--- 3. Melakukan Split Ulang (dengan fitur baru) ---\")\n",
        "\n",
        "    X_train_ultra, X_val_ultra, y_train_ultra, y_val_ultra = train_test_split(\n",
        "        X_scaled_ultra, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"--- 4. Melatih Ulang Model LGBM Terbaik (best_lgbm_tuned) ---\")\n",
        "\n",
        "    if 'best_lgbm_tuned' in locals():\n",
        "        best_lgbm_tuned.fit(X_train_ultra, y_train_ultra)\n",
        "\n",
        "        print(\"--- Model berhasil dilatih ulang ---\")\n",
        "\n",
        "        # --- 5. Evaluasi Model Ultra ---\n",
        "        print(\"\\n--- Mengevaluasi Model (dgn Fitur Installments) pada Data Validasi ---\")\n",
        "\n",
        "        y_pred_ultra = best_lgbm_tuned.predict(X_val_ultra)\n",
        "        y_proba_ultra = best_lgbm_tuned.predict_proba(X_val_ultra)[:, 1]\n",
        "\n",
        "        print(\"\\n--- Hasil Evaluasi (LGBM + Semua Fitur) ---\")\n",
        "\n",
        "        auc_ultra = roc_auc_score(y_val_ultra, y_proba_ultra)\n",
        "        print(f\"SKOR AUC-ROC ULTRA: {auc_ultra:.4f}  (Sebelumnya: 0.7651)\")\n",
        "\n",
        "        rec_ultra = recall_score(y_val_ultra, y_pred_ultra)\n",
        "        print(f\"Recall ULTRA:       {rec_ultra:.4f}  (Sebelumnya: 0.6896)\")\n",
        "\n",
        "        prec_ultra = precision_score(y_val_ultra, y_pred_ultra)\n",
        "        print(f\"Precision ULTRA:    {prec_ultra:.4f}  (Sebelumnya: 0.1715)\")\n",
        "\n",
        "        # Tampilkan CM baru\n",
        "        cm_ultra = confusion_matrix(y_val_ultra, y_pred_ultra)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm_ultra, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Prediksi Lancar (0)', 'Prediksi Gagal Bayar (1)'],\n",
        "                    yticklabels=['Aktual Lancar (0)', 'Aktual Gagal Bayar (1)'])\n",
        "        plt.ylabel('Aktual')\n",
        "        plt.xlabel('Prediksi')\n",
        "        plt.title('Confusion Matrix - LGBM + Semua Fitur', fontsize=16)\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"\\n--- ERROR: 'best_lgbm_tuned' tidak ditemukan. Jalankan Sel 16 (Tuning) terlebih dahulu. ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- ERROR: Data yang dibutuhkan tidak ditemukan. Jalankan Sel 21 & 23. ---\")"
      ],
      "metadata": {
        "id": "OTxF0Lb51idE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}